{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bff5e9ed-7e25-4e4b-bf90-7f3ef51d7572",
   "metadata": {},
   "source": [
    "# Classificação do texto por Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95885d4-f59d-4f44-9a9a-8eb50e952bcd",
   "metadata": {},
   "source": [
    "Vai classificar se o texto de entrada se trata de alegria ou medo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ed72ed-4bf5-4d8b-97e6-7f8058a08c64",
   "metadata": {},
   "source": [
    "## Biblioteca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2e2607e-5653-40d4-9026-f84c501ad371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c822141-f25d-4477-b82d-7b116e68d428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab05abb9-5904-439b-8926-af655944bfcf",
   "metadata": {},
   "source": [
    "## Base de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e621d0af-5688-4a7b-97ca-cb47e848faf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = [('eu sou admirada por muitos','alegria'),\n",
    "        ('me sinto completamente amado','alegria'),\n",
    "        ('amar e maravilhoso','alegria'),\n",
    "        ('estou me sentindo muito animado novamente','alegria'),\n",
    "        ('eu estou muito bem hoje','alegria'),\n",
    "        ('que belo dia para dirigir um carro novo','alegria'),\n",
    "        ('o dia está muito bonito','alegria'),\n",
    "        ('estou contente com o resultado do teste que fiz no dia de ontem','alegria'),\n",
    "        ('o amor e lindo','alegria'),\n",
    "        ('nossa amizade e amor vai durar para sempre', 'alegria'),\n",
    "        ('estou amedrontado', 'medo'),\n",
    "        ('ele esta me ameacando a dias', 'medo'),\n",
    "        ('isso me deixa apavorada', 'medo'),\n",
    "        ('este lugar e apavorante', 'medo'),\n",
    "        ('se perdermos outro jogo seremos eliminados e isso me deixa com pavor', 'medo'),\n",
    "        ('tome cuidado com o lobisomem', 'medo'),\n",
    "        ('se eles descobrirem estamos encrencados', 'medo'),\n",
    "        ('estou tremendo de medo', 'medo'),\n",
    "        ('eu tenho muito medo dele', 'medo'),\n",
    "        ('estou com medo do resultado dos meus testes', 'medo')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84391d5a-cde0-4256-ba23-e4d827146b39",
   "metadata": {},
   "source": [
    "## Tratamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31b04ceb-ee85-432c-b192-75eb8b06b0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Recebe tuplas que contém (frase,classe) trata frases e retorna \"tokenizada\" sem \"stopwords\" e apenas \"radicais\" '''\n",
    "\n",
    "def aplicastemmer(texto):\n",
    "    \n",
    "    stopwordsnltk = nltk.corpus.stopwords.words('portuguese')\n",
    "    \n",
    "    stemmer = nltk.stem.RSLPStemmer() # compatível com portugues\n",
    "    \n",
    "    frases_stemming = []\n",
    "    \n",
    "    for (palavras,emocao) in texto:\n",
    "        \n",
    "        comstemming = [str(stemmer.stem(p)) for p in palavras.split() if p not in stopwordsnltk] # Aplica stemmer e também retira stopwords\n",
    "        \n",
    "        frases_stemming.append((comstemming,emocao))\n",
    "        \n",
    "    return frases_stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e28672f-b9ba-427b-87fb-241b642b5dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "frases_c_steeming = aplicastemmer(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cf09d52-4a41-4da1-ae77-f33f46615a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['admir', 'muit'], 'alegria'),\n",
       " (['sint', 'complet', 'am'], 'alegria'),\n",
       " (['am', 'maravilh'], 'alegria'),\n",
       " (['sent', 'anim', 'nov'], 'alegria'),\n",
       " (['bem', 'hoj'], 'alegria'),\n",
       " (['bel', 'dia', 'dirig', 'carr', 'nov'], 'alegria'),\n",
       " (['dia', 'bonit'], 'alegria'),\n",
       " (['cont', 'result', 'test', 'fiz', 'dia', 'ont'], 'alegria'),\n",
       " (['am', 'lind'], 'alegria'),\n",
       " (['amizad', 'am', 'vai', 'dur', 'sempr'], 'alegria'),\n",
       " (['amedront'], 'medo'),\n",
       " (['ameac', 'dia'], 'medo'),\n",
       " (['deix', 'apavor'], 'medo'),\n",
       " (['lug', 'apavor'], 'medo'),\n",
       " (['perd', 'outr', 'jog', 'elimin', 'deix', 'pav'], 'medo'),\n",
       " (['tom', 'cuid', 'lobisom'], 'medo'),\n",
       " (['descobr', 'encrenc'], 'medo'),\n",
       " (['trem', 'med'], 'medo'),\n",
       " (['med'], 'medo'),\n",
       " (['med', 'result', 'test'], 'medo')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frases_c_steeming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14444a29-589d-4012-b6b1-849bf9f5dd71",
   "metadata": {},
   "source": [
    "## Criando Base de Dados que alimenta o algoritimo\n",
    "\n",
    "Palavras únicas e rótulos\n",
    "\n",
    "Tabela S/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dcaa226-0965-4fb9-982a-ec419c607a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando lista com todas palavras que aparecem na base\n",
    "# Recebe frase pré-processada (tokens - steeming)\n",
    "\n",
    "def buscapalavras(frase):\n",
    "    todaspalavras=[]\n",
    "    \n",
    "    for (palavras,emocao) in frase:\n",
    "        todaspalavras.extend(palavras) # extend mescla as palavras cria uma lista com as listas passadas no extend\n",
    "        \n",
    "    return todaspalavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87766d91-5a33-430e-92d4-803a7a81ee2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admir',\n",
       " 'muit',\n",
       " 'sint',\n",
       " 'complet',\n",
       " 'am',\n",
       " 'am',\n",
       " 'maravilh',\n",
       " 'sent',\n",
       " 'anim',\n",
       " 'nov']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_palavras = buscapalavras(frases_c_steeming); # retorna lista de palavras \n",
    "lista_palavras[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7c07b19-4d25-4fd0-b275-667c61ad07f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscafrequencia(palavras): # parâmetro lista de palavras \n",
    "    \n",
    "    palavras = nltk.FreqDist(palavras)\n",
    "    \n",
    "    return palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0348e0c-cf40-43bb-b9f3-8ad2d7f6ba09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'am': 4, 'dia': 4, 'med': 3, 'nov': 2, 'result': 2, 'test': 2, 'deix': 2, 'apavor': 2, 'admir': 1, 'muit': 1, ...})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_palavras = buscafrequencia(lista_palavras)\n",
    "freq_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d75684aa-54d0-45e0-ac16-d88805d5f92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscapalavrasunicas(frequencia):\n",
    "    \n",
    "    freq = frequencia.keys() # Já retorna valores únicos de \"chaves\" ou seja remove duplicados;\n",
    "    \n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fa6fb1f-6529-4539-ad09-e7fad109533e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['admir', 'muit', 'sint', 'complet', 'am', 'maravilh', 'sent', 'anim', 'nov', 'bem', 'hoj', 'bel', 'dia', 'dirig', 'carr', 'bonit', 'cont', 'result', 'test', 'fiz', 'ont', 'lind', 'amizad', 'vai', 'dur', 'sempr', 'amedront', 'ameac', 'deix', 'apavor', 'lug', 'perd', 'outr', 'jog', 'elimin', 'pav', 'tom', 'cuid', 'lobisom', 'descobr', 'encrenc', 'trem', 'med'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_unicas = buscapalavrasunicas(freq_palavras)\n",
    "palavras_unicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8729d308-c6be-4fd8-9a52-7964f0a00700",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Responsável por checar as frases recebidas e verificar se True ou False na tabela'\n",
    "\n",
    "def extrator_palavras(documento):\n",
    "    \n",
    "    doc = set(documento)\n",
    "    \n",
    "    caract = {} # dicionário que vai dizer se existe ou não a palavra\n",
    "    \n",
    "    for palavra in palavras_unicas:\n",
    "        \n",
    "        caract['%s' % palavra] = (palavra in doc) # Palavra(chave) : Bool\n",
    "        \n",
    "    return caract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b85d1b83-70a3-4dce-942e-d51043ac2c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'admir': False,\n",
       " 'muit': False,\n",
       " 'sint': False,\n",
       " 'complet': False,\n",
       " 'am': True,\n",
       " 'maravilh': False,\n",
       " 'sent': False,\n",
       " 'anim': False,\n",
       " 'nov': True,\n",
       " 'bem': False,\n",
       " 'hoj': False,\n",
       " 'bel': False,\n",
       " 'dia': True,\n",
       " 'dirig': False,\n",
       " 'carr': False,\n",
       " 'bonit': False,\n",
       " 'cont': False,\n",
       " 'result': False,\n",
       " 'test': False,\n",
       " 'fiz': False,\n",
       " 'ont': False,\n",
       " 'lind': False,\n",
       " 'amizad': False,\n",
       " 'vai': False,\n",
       " 'dur': False,\n",
       " 'sempr': False,\n",
       " 'amedront': False,\n",
       " 'ameac': False,\n",
       " 'deix': False,\n",
       " 'apavor': False,\n",
       " 'lug': False,\n",
       " 'perd': False,\n",
       " 'outr': False,\n",
       " 'jog': False,\n",
       " 'elimin': False,\n",
       " 'pav': False,\n",
       " 'tom': False,\n",
       " 'cuid': False,\n",
       " 'lobisom': False,\n",
       " 'descobr': False,\n",
       " 'encrenc': False,\n",
       " 'trem': False,\n",
       " 'med': False}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caract_frase = extrator_palavras(['am','nov','dia'])\n",
    "caract_frase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7c8516-f47a-4369-a0ed-c71390b537ff",
   "metadata": {},
   "source": [
    "## Base Completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "152d7f5a-58e8-427f-a449-13fafdcde63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['admir', 'muit'], 'alegria'),\n",
       " (['sint', 'complet', 'am'], 'alegria'),\n",
       " (['am', 'maravilh'], 'alegria'),\n",
       " (['sent', 'anim', 'nov'], 'alegria'),\n",
       " (['bem', 'hoj'], 'alegria'),\n",
       " (['bel', 'dia', 'dirig', 'carr', 'nov'], 'alegria'),\n",
       " (['dia', 'bonit'], 'alegria'),\n",
       " (['cont', 'result', 'test', 'fiz', 'dia', 'ont'], 'alegria'),\n",
       " (['am', 'lind'], 'alegria'),\n",
       " (['amizad', 'am', 'vai', 'dur', 'sempr'], 'alegria'),\n",
       " (['amedront'], 'medo'),\n",
       " (['ameac', 'dia'], 'medo'),\n",
       " (['deix', 'apavor'], 'medo'),\n",
       " (['lug', 'apavor'], 'medo'),\n",
       " (['perd', 'outr', 'jog', 'elimin', 'deix', 'pav'], 'medo'),\n",
       " (['tom', 'cuid', 'lobisom'], 'medo'),\n",
       " (['descobr', 'encrenc'], 'medo'),\n",
       " (['trem', 'med'], 'medo'),\n",
       " (['med'], 'medo'),\n",
       " (['med', 'result', 'test'], 'medo')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frases_c_steeming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "175f551d-9397-4d4f-9478-fce175b895d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'admir': True, 'muit': True, 'sint': False, 'complet': False, 'am': False, 'maravilh': False, 'sent': False, 'anim': False, 'nov': False, 'bem': False, 'hoj': False, 'bel': False, 'dia': False, 'dirig': False, 'carr': False, 'bonit': False, 'cont': False, 'result': False, 'test': False, 'fiz': False, 'ont': False, 'lind': False, 'amizad': False, 'vai': False, 'dur': False, 'sempr': False, 'amedront': False, 'ameac': False, 'deix': False, 'apavor': False, 'lug': False, 'perd': False, 'outr': False, 'jog': False, 'elimin': False, 'pav': False, 'tom': False, 'cuid': False, 'lobisom': False, 'descobr': False, 'encrenc': False, 'trem': False, 'med': False}, 'alegria'), ({'admir': False, 'muit': False, 'sint': True, 'complet': True, 'am': True, 'maravilh': False, 'sent': False, 'anim': False, 'nov': False, 'bem': False, 'hoj': False, 'bel': False, 'dia': False, 'dirig': False, 'carr': False, 'bonit': False, 'cont': False, 'result': False, 'test': False, 'fiz': False, 'ont': False, 'lind': False, 'amizad': False, 'vai': False, 'dur': False, 'sempr': False, 'amedront': False, 'ameac': False, 'deix': False, 'apavor': False, 'lug': False, 'perd': False, 'outr': False, 'jog': False, 'elimin': False, 'pav': False, 'tom': False, 'cuid': False, 'lobisom': False, 'descobr': False, 'encrenc': False, 'trem': False, 'med': False}, 'alegria'), ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_completa = nltk.classify.apply_features(extrator_palavras,frases_c_steeming)\n",
    "base_completa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92614e07-dc2e-411c-88d4-55b0ac305ac7",
   "metadata": {},
   "source": [
    "## Naive Bayes - Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb11e383-e038-4b24-8730-da75b36b7daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recebe base de dados e cria tabela de probabilidade;\n",
    "\n",
    "classificador = nltk.NaiveBayesClassifier.train(base_completa) #base completa é a tabela de palavras únicas tratadas;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b5beba1-451f-43a4-a53c-491184fc9296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alegria', 'medo']\n"
     ]
    }
   ],
   "source": [
    "# Retorna os possíveis classificadores.\n",
    "\n",
    "print(classificador.labels()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e8a0f6f-c523-489c-9315-e6830fdf946d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                     dia = True           alegri : medo   =      2.3 : 1.0\n",
      "                      am = False            medo : alegri =      1.6 : 1.0\n",
      "                     med = False          alegri : medo   =      1.4 : 1.0\n",
      "                     dia = False            medo : alegri =      1.3 : 1.0\n",
      "                  apavor = False          alegri : medo   =      1.2 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Retorna tabela com os x_números mais informativos de classificar os rótulos;\n",
    "\n",
    "print(classificador.show_most_informative_features(5)) \n",
    "\n",
    "# Dia = True a prob de ser alegria é 2.3 x maior que medo\n",
    "\n",
    "# am- amor = False a prob de ser medo é 1.6 x maior que alegria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db63da7d-500f-4530-b692-695e8dedc327",
   "metadata": {},
   "source": [
    "# Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "74b0586b-8c5c-436c-9469-17d3b33851fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Função v2 personalizada para receber frase e voltar com texto tratado pro algoritimo'''\n",
    "\n",
    "def aplicastemmer_v2(texto):\n",
    "    \n",
    "    stopwordsnltk = nltk.corpus.stopwords.words('portuguese')\n",
    "    \n",
    "    stemmer = nltk.stem.RSLPStemmer() # compatível com portugues\n",
    "   \n",
    "    comstemming = [str(stemmer.stem(p)) for p in texto.split() if p not in stopwordsnltk] # Aplica stemmer e também retira stopwords\n",
    "        \n",
    "    return  comstemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "34bd4187-5845-4207-905c-5f9d2194edb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = 'eu estou muito feliz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2b46af66-ce0a-43f3-88f1-c27cefc80adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feliz']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aplicastemmer_v2(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d1375637-757a-4d0a-bf72-39db85cfdbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'admir': False,\n",
       " 'muit': False,\n",
       " 'sint': False,\n",
       " 'complet': False,\n",
       " 'am': False,\n",
       " 'maravilh': False,\n",
       " 'sent': False,\n",
       " 'anim': False,\n",
       " 'nov': False,\n",
       " 'bem': False,\n",
       " 'hoj': False,\n",
       " 'bel': False,\n",
       " 'dia': False,\n",
       " 'dirig': False,\n",
       " 'carr': False,\n",
       " 'bonit': False,\n",
       " 'cont': False,\n",
       " 'result': False,\n",
       " 'test': False,\n",
       " 'fiz': False,\n",
       " 'ont': False,\n",
       " 'lind': False,\n",
       " 'amizad': False,\n",
       " 'vai': False,\n",
       " 'dur': False,\n",
       " 'sempr': False,\n",
       " 'amedront': False,\n",
       " 'ameac': False,\n",
       " 'deix': False,\n",
       " 'apavor': False,\n",
       " 'lug': False,\n",
       " 'perd': False,\n",
       " 'outr': False,\n",
       " 'jog': False,\n",
       " 'elimin': False,\n",
       " 'pav': False,\n",
       " 'tom': False,\n",
       " 'cuid': False,\n",
       " 'lobisom': False,\n",
       " 'descobr': False,\n",
       " 'encrenc': False,\n",
       " 'trem': False,\n",
       " 'med': False}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Texto precisa estar no mesmo formato de como a base_completa foi tratada.\n",
    "\n",
    "novo = extrator_palavras(aplicastemmer_v2(teste))\n",
    "novo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "94f168eb-3f47-4a0a-af65-a8de342a9129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'medo'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classificador usa método classify para classificar nova frase.\n",
    "\n",
    "classificador.classify(novo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0d1a9d82-7ab3-4920-aedf-857a9bda4221",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribuicao = classificador.prob_classify(novo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "911f14c5-1390-4034-a44f-91a41441ca37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alegria: 0.295511\n",
      "medo: 0.704489\n"
     ]
    }
   ],
   "source": [
    "distribuicao = classificador.prob_classify(novo)\n",
    "\n",
    "for classe in distribuicao.samples():\n",
    "    \n",
    "    print(\"%s: %f\"%(classe,distribuicao.prob(classe)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
